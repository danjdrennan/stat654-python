{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>STAT 654: Statistical Computing with R and Python</h1>\n",
    "<h2>Intro Python for Data Analysis</h2>\n",
    "<strong>\n",
    "Daniel Drennan<br>\n",
    "Dr. Sharmistha Guha<br><br>\n",
    "Department of Statistics<br>\n",
    "Texas A&M University<br>\n",
    "College Station, TX, USA<br><br>\n",
    "Spring 2022<br>\n",
    "</strong>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical python imports (not used here)\n",
    "import os\n",
    "import functools\n",
    "\n",
    "# standard scipy imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "We are going to use two data sources, one for regression and one for classification. Respectively, they are listed below.\n",
    "\n",
    "1. Auto MPG. (1993). UCI Machine Learning Repository. <https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/>\n",
    "\n",
    "2. Fisher, R.A.. (1988). Iris. UCI Machine Learning Repository. <https://archive.ics.uci.edu/ml/machine-learning-databases/iris/>\n",
    "\n",
    "We can in principle read these data directly from the web without downloading them, which I'll demonstrate.\n",
    "However, it makes more sense to download the data directly to your machine to reduce the number of times the main page is queried (it is often the case that you'll rerun cells where you load a dataset).\n",
    "A code to run from your terminal. \n",
    "\n",
    "```bash\n",
    "# locally download the auto-mpg data\n",
    "curl -o data/auto-mpg.data archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
    "curl -o data/auto-mpg.names archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.names\n",
    "# locally download the iris data\n",
    "curl -o data/iris.data archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "curl -o data/iris.data archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.names\n",
    "```\n",
    "\n",
    "The main Python library for working with data is Pandas.\n",
    "Our first step will be to load the two datasets and then we'll look at how to create new features using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automobile MPG data for a regression problem\n",
    "# The data does not include headers, so we must read and add them manually\n",
    "# See archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/ for details\n",
    "auto_url = \"data/auto-mpg.data\"\n",
    "auto_names = [\n",
    "    \"mpg\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "    \"model_year\",\n",
    "    \"origin\",\n",
    "    \"car_name\"\n",
    "]\n",
    "\n",
    "# auto = pd.read_table(auto_url, na_values=\"?\", names=auto_names)\n",
    "auto = pd.read_fwf(auto_url, na_values = \"?\", names=auto_names)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris data available from archive.ics.uci.edu/ml/machine-learning-databases/iris/\n",
    "# to perform a classification problem\n",
    "iris_path = \"data/iris.data\"\n",
    "\n",
    "# The column names are not stored in the data, so we must provide them\n",
    "iris_names = [\n",
    "    \"sepal_length\",\n",
    "    \"sepal_width\",\n",
    "    \"petal_length\",\n",
    "    \"petal_width\",\n",
    "    \"species\"\n",
    "]\n",
    "\n",
    "# Now load the data and preview it\n",
    "iris = pd.read_csv(iris_path, names = iris_names)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for a dataframe\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Data\n",
    "\n",
    "It is very typical to transform imported data in some way before actually working with it.\n",
    "From creating new variables to rescaling existing ones, we can do a lot of stuff compactly using pandas.\n",
    "A few of these ideas are templated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a categorical variable to a 0-1 indicator (dummy) variable\n",
    "pd.get_dummies(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Iris-\" part of each species string is redundant, so let's strip it off every description in one clean pass\n",
    "# There are multiple ways to do this, but we'll strive for one that is pretty elegant\n",
    "iris['species'] = iris.species.apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we wanted to transform mpg to kpg (kilometers per gallon instead of miles per gallon)\n",
    "# We can create a new variable as follows\n",
    "auto[\"kml\"] = auto.mpg / 2.35214583\n",
    "\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making scatterplot matrices with a dataframe (does not scale well for very large datasets)\n",
    "plot_vars = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "sns.pairplot(auto, vars=plot_vars, hue=\"origin\", palette=\"viridis\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.boxplot_frame_groupby(iris.groupby(\"species\"), figsize=(12,12))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Hypothesis testing in Python can be underwhelming when compared with R.\n",
    "The outputs in Python are not nearly as informative as those in R.\n",
    "Based on the last graph we made, we can form a hypothesis about the difference in sepal widths\n",
    "between setosa and versicolor plants and conduct a two sample t test on the result.\n",
    "The result is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor_sepal_width = iris[iris.species == \"versicolor\"].sepal_width.to_numpy()\n",
    "setosa_sepal_width = iris[iris.species == \"setosa\"].sepal_width.to_numpy()\n",
    "\n",
    "t_test = sp.stats.ttest_ind(versicolor_sepal_width, setosa_sepal_width, equal_var=False)\n",
    "\n",
    "test_stat = t_test[0]\n",
    "p_value = t_test[1]\n",
    "\n",
    "print(\"H0: Average Sepal Widths of Versicolor and Setosa flower strains are equivalent\")\n",
    "print(f\"T = {test_stat:.4f} with p-value {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example which is more concrete is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want this to be deterministically repeatable, so I'm setting a random seed now.\n",
    "np.random.seed(1)\n",
    "\n",
    "# For this demonstration, I want to construct two datasets which are similar and \n",
    "# compare their means using the t test shown before\n",
    "y = np.random.normal(loc=100, scale=30, size=(1000, 2))\n",
    "\n",
    "# Conduct a two-sample test with the data just simulated\n",
    "ttest = sp.stats.ttest_ind(y[0], y[1], equal_var=True)\n",
    "\n",
    "print(\"Two sample t test\\nMean1: {:.4f}\\tMean2: {:.4f}\\tT-stat: {:.4f}\\tp-value: {:.6f}\".format(*y.mean(axis=0), *ttest))\n",
    "\n",
    "# One sample test\n",
    "onesample = sp.stats.ttest_1samp(y[1], 60)\n",
    "\n",
    "print(\"One sample t test\\nMean: {:.4f}\\tT-stat: {:.4f}\\t\\tp-value: {:.6f}\".format(y[1].mean(), *onesample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the last two datasets to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a figure and specify its size\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Always label your plots\n",
    "plt.title(\"Two Samples $Y_1, Y_2 ~ N(100, 30)$\")\n",
    "plt.xlabel(\"Sampled Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Plot histograms\n",
    "for _ in range(2):\n",
    "    plt.hist(y[:, _], bins=20, color=f\"C{_}\", alpha=0.75, label=f\"$Y_{_+1}$\")\n",
    "\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sample t-tests shown before neglect most of the information in our datasets.\n",
    "Moreover, they answer relatively uninteresting questions about differences in features.\n",
    "We can do better by building classifiers and regression models of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making scatterplot matrices with a dataframe (does not scale well for very large datasets)\n",
    "plot_vars = [\"mpg\", \"cylinders\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "sns.pairplot(auto, vars=plot_vars, hue=\"origin\", palette=\"viridis\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = sm.OLS.from_formula(\n",
    "    \"mpg ~ weight + acceleration + model_year + origin\", \n",
    "    data=auto).fit()\n",
    "auto_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same model, but with interactions\n",
    "# The string splitting method can be handy for converting a string into a list\n",
    "vars = \"weight + acceleration + model_year + origin\".split(\" + \")\n",
    "# First we need to convolve the vars list just constructed to build the interactions\n",
    "interactions = []\n",
    "for j in range(3):\n",
    "    for k in range(4):\n",
    "        interactions.append(f\"{vars[j]}*{vars[k]}\")\n",
    "\n",
    "# Now we can recombine the interactions as the RHS of the formula\n",
    "formula = \"mpg ~ \" + \" + \".join(interactions)\n",
    "\n",
    "auto_model2 = sm.OLS.from_formula(formula, data = auto).fit()\n",
    "auto_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(auto_model2.pvalues, \"o\", mfc=\"none\", markersize=10)\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "# Labels / formatting\n",
    "plt.title(\"Auto-Mpg model with first order interactions\", fontsize=24)\n",
    "plt.xlabel(\"Model Term\", fontsize=16)\n",
    "plt.ylabel(\"p-value\", fontsize=16)\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "plt.hlines(0.05, 0, len(interactions)-2, color=\"steelblue\", linestyles=\"-.\", linewidth=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbf4d2edc3960937e4167eae6bb30e657db03bac26e45aa5902de594be292864"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('stats': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
